import streamlit as st
import pdfplumber
from nltk.tokenize import sent_tokenize
from sklearn.feature_extraction.text import TfidfVectorizer
import openai
from transformers import pipeline
import tempfile
import os

# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="Brisbane ë°”ë‘‘íšŒ",
    page_icon="ğŸ“š",
    layout="wide"
)

# íƒ€ì´í‹€
st.title("ğŸ“š Brisnane ë°”ë‘‘ íšŒ")
st.markdown("ì •ì‹  ìˆ˜ì–‘ì„ ìœ„í•œ ë„ì¥,  ì…íšŒ ì‹œí—˜ë¬¸ì œ")

# ì‚¬ì´ë“œë°” ì„¤ì •
with st.sidebar:
    st.header("")
    
    # API í‚¤ ì…ë ¥
    # openai_api_key = st.text_input(
    #     "OpenAI API í‚¤",
    #     type="password",
    #     placeholder="sk-...",
    #     help="OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”"
    # )
    
    openai_api_key = st.secrets["api_keys"]["my_api_key"] 

    # ë¬¸ì œ ìƒì„± ì˜µì…˜
    st.subheader("ë¬¸ì œ ìƒì„± ì˜µì…˜")
    use_openai = st.checkbox("OpenAI GPT-4 ì‚¬ìš©", value=True)
    use_huggingface = st.checkbox("HuggingFace ëª¨ë¸ ì‚¬ìš©", value=False)
    use_openai = st.checkbox("", value=True)
    use_huggingface = st.checkbox("", value=False)
    
    # í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ
    text_limit = st.slider(
        "í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ (ë¬¸ì)",
        min_value=500,
        max_value=5000,
        value=3000,
        step=500
    )

# íŒŒì¼ ì—…ë¡œë“œ ì„¹ì…˜
# uploaded_file = st.file_uploader(
#     "PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”",
#     type="pdf",
#     help="ë¬¸ì œë¥¼ ìƒì„±í•  PDF íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”"
# )
uploaded_file = "go-question.pdf"

with open(uploaded_file, 'rb') as f:
    pdf_content = f.read()
    # ì´ì œ pdf_contentë¥¼ ì‚¬ìš©í•˜ì—¬ í•„ìš”í•œ ì‘ì—… ìˆ˜í–‰

def extract_text_from_pdf(pdf_file_path):
    """PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    with open(pdf_file_path, 'rb') as pdf_file:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
            tmp_file.write(pdf_file.read())
            tmp_path = tmp_file.name

    try:
        with pdfplumber.open(tmp_path) as pdf:
            text = "".join(page.extract_text() or "" for page in pdf.pages)
        return text
    finally:
        # tmp_path íŒŒì¼ ì‚­ì œ (optional)
        os.remove(tmp_path)


# def extract_text_from_pdf(pdf_file):
#     """PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
#     with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
#         tmp_file.write(pdf_file.read())
#         tmp_path = tmp_file.name
    
#     try:
#         with pdfplumber.open(tmp_path) as pdf:
#             text = "".join(page.extract_text() or "" for page in pdf.pages)
#         return text
#     finally:
#         os.unlink(tmp_path)

def preprocess_text(text):
    """í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬"""
    # ë¬¸ì¥ ë¶„í• 
    sentences = sent_tokenize(text)
    
    # í‚¤ì›Œë“œ ì¶”ì¶œ
    # keywords =  # ë˜ëŠ” None
    keywords = []
    if 'keywords' in locals() and keywords:
    # keywordsê°€ ì¡´ì¬í•˜ê³  ë¹„ì–´ìˆì§€ ì•Šì€ ê²½ìš°ì˜ ì²˜ë¦¬
    #f keywords.any():  # ë˜ëŠ” if len(keywords) > 0:
        try:
            vectorizer = TfidfVectorizer(max_features=50, stop_words='english')
            keywords_matrix = vectorizer.fit_transform([text])
            feature_names = vectorizer.get_feature_names_out()
            keywords = feature_names[:10]  # ìƒìœ„ 10ê°œ í‚¤ì›Œë“œ
        except:
            keywords = []
    
    return sentences, keywords

def generate_questions_with_openai(text, api_key, text_limit):
    """OpenAIë¥¼ ì‚¬ìš©í•˜ì—¬ ë¬¸ì œ ìƒì„±"""
    if not api_key:
        return "âŒ OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."
    
    openai.api_key = api_key
    
    prompt = f"""
    ë‹¤ìŒ í…ìŠ¤íŠ¸ì—ì„œ ë‹¤ì–‘í•œ ìœ í˜•ì˜ ë¬¸ì œë¥¼ ê°ê° 1ê°œì”© ìƒì„±í•´ì£¼ì„¸ìš”.
    ê° ë¬¸ì œì—ëŠ” ì •ë‹µê³¼ ì„¤ëª…ì„ í¬í•¨í•´ì£¼ì„¸ìš”.
    
    ìƒì„±í•  ë¬¸ì œ ìœ í˜•:
    - ê°ê´€ì‹ ë¬¸ì œ (Multiple Choice)
    - ì£¼ê´€ì‹ ë¬¸ì œ (Short Answer)
    - ì§„ìœ„í˜• ë¬¸ì œ (True/False)
    - ë¹ˆì¹¸ ì±„ìš°ê¸° ë¬¸ì œ (Fill-in-the-Blank)
    - ì—°ê²°í˜• ë¬¸ì œ (Matching)
    
    í…ìŠ¤íŠ¸: {text[:text_limit]}
    
    ì¶œë ¥ í˜•ì‹:
    ê° ë¬¸ì œëŠ” ë‹¤ìŒê³¼ ê°™ì€ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”:
    [ìœ í˜•] ë¬¸ì œ ì œëª©
    â“ ë¬¸ì œ ë‚´ìš©
    âœ… ì •ë‹µ: 
    ğŸ’¡ ì„¤ëª…:
    ---
    """
    
    try:
        response = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=2000,
            temperature=0.7
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"âŒ OpenAI API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

def generate_questions_with_huggingface(text):
    """HuggingFace ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë¬¸ì œ ìƒì„±"""
    try:
        qa_generator = pipeline(
            "text2text-generation", 
            model="mrm8488/t5-base-finetuned-question-generation-ap"
        )
        generated_questions = qa_generator(text[:512])
        return generated_questions
    except Exception as e:
        return f"âŒ HuggingFace ëª¨ë¸ í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

# ë©”ì¸ ì²˜ë¦¬ ë¡œì§
if uploaded_file is not None:
    # ì§„í–‰ë¥  í‘œì‹œê¸°
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    # 1. í…ìŠ¤íŠ¸ ì¶”ì¶œ
    status_text.text("PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘...")
    extracted_text = extract_text_from_pdf(uploaded_file)
    progress_bar.progress(25)
    
    if not extracted_text.strip():
        st.error("âŒ PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ íŒŒì¼ì„ ì‹œë„í•´ì£¼ì„¸ìš”.")
        st.stop()
    
    # 2. í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
    status_text.text("í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ì¤‘...")
    sentences, keywords = preprocess_text(extracted_text)
    progress_bar.progress(50)
    
    # ì¶”ì¶œëœ ì •ë³´ í‘œì‹œ
    col1, col2 = st.columns(2)
    
    with col1:
        with st.expander("ğŸ“„ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°", expanded=False):
            st.text_area("í…ìŠ¤íŠ¸", extracted_text[:1000] + "..." if len(extracted_text) > 1000 else extracted_text, height=200)
    
    with col2:
        with st.expander("ğŸ” ì¶”ì¶œëœ í‚¤ì›Œë“œ", expanded=False):
            if keywords:
                st.write(", ".join(keywords))
            else:
                st.write("í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        with st.expander("ğŸ“Š í†µê³„", expanded=False):
            st.write(f"- ì´ ë¬¸ì ìˆ˜: {len(extracted_text):,}")
            st.write(f"- ë¬¸ì¥ ìˆ˜: {len(sentences)}")
            st.write(f"- ì‚¬ìš©ëœ í…ìŠ¤íŠ¸ ê¸¸ì´: {min(len(extracted_text), text_limit):,}")
    
    # 3. ë¬¸ì œ ìƒì„±
    status_text.text("ë¬¸ì œ ìƒì„± ì¤‘...")
    progress_bar.progress(75)
    
    # ê²°ê³¼ë¥¼ í‘œì‹œí•  íƒ­ ìƒì„±
    tab1, tab2 = st.tabs(["ğŸ“ ìƒì„±ëœ ë¬¸ì œ", "ğŸ”§ ìƒì„¸ ì •ë³´"])
    
    with tab1:
        st.subheader("ğŸ¤– AI ìƒì„± ë¬¸ì œ")
        
        # OpenAIë¥¼ ì‚¬ìš©í•œ ë¬¸ì œ ìƒì„±
        if use_openai:
            st.markdown("### OpenAI GPT-4ë¡œ ìƒì„±ëœ ë¬¸ì œ")
            with st.spinner("OpenAIê°€ ë¬¸ì œë¥¼ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                openai_questions = generate_questions_with_openai(
                    extracted_text, openai_api_key, text_limit
                )
            
            if openai_questions.startswith("âŒ"):
                st.error(openai_questions)
            else:
                # ìƒì„±ëœ ë¬¸ì œë¥¼ ë³´ê¸° ì¢‹ê²Œ formatting
                questions_display = openai_questions.replace("âœ…", "\nâœ…")
                questions_display = questions_display.replace("ğŸ’¡", "\nğŸ’¡")
                questions_display = questions_display.replace("---", "\n" + "="*50 + "\n")
                
                st.markdown(questions_display)
        
        # HuggingFaceë¥¼ ì‚¬ìš©í•œ ë¬¸ì œ ìƒì„±
        if use_huggingface:
            st.markdown("### HuggingFace ëª¨ë¸ë¡œ ìƒì„±ëœ ë¬¸ì œ")
            with st.spinner("HuggingFace ëª¨ë¸ì´ ë¬¸ì œë¥¼ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                hf_questions = generate_questions_with_huggingface(extracted_text)
            
            if isinstance(hf_questions, list):
                for i, q in enumerate(hf_questions, 1):
                    st.write(f"**Q{i}:** {q.get('generated_text', '')}")
            else:
                st.error(hf_questions)
    
    with tab2:
        st.subheader("ìƒì„¸ ì •ë³´")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("#### ë¬¸ì¥ ëª©ë¡")
            for i, sentence in enumerate(sentences[:10], 1):
                st.write(f"{i}. {sentence}")
            
            if len(sentences) > 10:
                st.info(f"... ì™¸ {len(sentences) - 10}ê°œ ë¬¸ì¥ ë” ìˆìŒ")
        
        with col2:
            st.markdown("#### ì²˜ë¦¬ ë¡œê·¸")
            st.success("âœ… PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ")
            st.success("âœ… í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ì™„ë£Œ")
            if use_openai:
                if openai_questions and not openai_questions.startswith("âŒ"):
                    st.success("âœ… OpenAI ë¬¸ì œ ìƒì„± ì™„ë£Œ")
                else:
                    st.error("âŒ OpenAI ë¬¸ì œ ìƒì„± ì‹¤íŒ¨")
            if use_huggingface:
                if isinstance(hf_questions, list):
                    st.success("âœ… HuggingFace ë¬¸ì œ ìƒì„± ì™„ë£Œ")
                else:
                    st.error("âŒ HuggingFace ë¬¸ì œ ìƒì„± ì‹¤íŒ¨")
    
    # ì§„í–‰ë¥  ì™„ë£Œ
    progress_bar.progress(100)
    status_text.text("âœ… ë¬¸ì œ ìƒì„± ì™„ë£Œ!")
    
    # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
    if use_openai and openai_questions and not openai_questions.startswith("âŒ"):
        st.download_button(
            label="ğŸ“¥ ìƒì„±ëœ ë¬¸ì œ ë‹¤ìš´ë¡œë“œ",
            data=openai_questions,
            file_name="generated_questions.txt",
            mime="text/plain"
        )

else:
    # íŒŒì¼ ì—…ë¡œë“œ ì „ ì•ˆë‚´ ë©”ì‹œì§€
    st.info("ğŸ‘† ì‚¬ì´ë“œë°”ì—ì„œ ì„¤ì •ì„è°ƒæ•´í•˜ê³  PDF íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
    
    # ì‚¬ìš©ë²• ì•ˆë‚´
    with st.expander("ğŸ“– ì‚¬ìš©ë²•", expanded=True):
        st.markdown("""
        1. **íŒŒì¼ ì—…ë¡œë“œ**: ë¬¸ì œë¥¼ ìƒì„±í•  PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”
        2. **API ì„¤ì •**: OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì„ íƒì‚¬í•­)
        3. **ëª¨ë¸ ì„ íƒ**: ì‚¬ìš©í•  AI ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”
        4. **ìƒì„± ì‹œì‘**: íŒŒì¼ ì—…ë¡œë“œ í›„ ìë™ìœ¼ë¡œ ë¬¸ì œê°€ ìƒì„±ë©ë‹ˆë‹¤
        
        **ì§€ì›ë˜ëŠ” ë¬¸ì œ ìœ í˜•:**
        - ê°ê´€ì‹ ë¬¸ì œ
        - ì£¼ê´€ì‹ ë¬¸ì œ  
        - ì§„ìœ„í˜• ë¬¸ì œ
        - ë¹ˆì¹¸ ì±„ìš°ê¸°
        - ì—°ê²°í˜• ë¬¸ì œ
        """)

# í‘¸í„°
st.markdown("---")
st.markdown(
    "<div style='text-align: center; color: gray;'>"
    "PDF ë¬¸ì œ ìƒì„±ê¸° | AI-powered Quiz Generator"
    "</div>",
    unsafe_allow_html=True
)